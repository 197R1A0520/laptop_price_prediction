# -*- coding: utf-8 -*-
"""laptop_price_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UF4QhnTSrLKsZyVmjx5yRpw31_7s2vfN
"""

##IMPORTING LIBRARIES
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
##LOAD THE DATASET
import pandas as pd
df = pd.read_csv('/content/laptop_price.csv' ,encoding='ISO-8859-1')
print(df)
# EDA
# 1.head of the dataset
print(df.head())
print(df.tail())
print(df.sample(10))
#2.the shape of the dataset
print(df.shape)
#3.list types of all columns
print(df.dtypes)
#4.info of the dataset
print(df.info())
#5.summary of the dataset
print(df.describe())
## DATA CLEANING
#1.drop the duplicates
print(df.shape)
df=df.drop_duplicates()
print(df.shape)
#2.check the NULL values
print(df.isnull().sum())
#for converting in number format
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df.Company = le.fit_transform(df.Company)
df.Product = le.fit_transform(df.Product)
df.TypeName = le.fit_transform(df.TypeName)
df.ScreenResolution = le.fit_transform(df.ScreenResolution)
df.Cpu = le.fit_transform(df.Cpu)
df.Ram = le.fit_transform(df.Ram)
df.Memory = le.fit_transform(df.Memory)
df.Gpu = le.fit_transform(df.Gpu)
df.OpSys = le.fit_transform(df.OpSys)
df.Weight = le.fit_transform(df.Weight)
print(df.info())
print(df.describe())
# create a ml model to predict the car prices based on different input features
print(df['Price_euros'])
print(df['Price_euros'].max())
print(df['Price_euros'].min())
import matplotlib.pyplot as plt
import seaborn as sns
sns.distplot(df['Price_euros'])
plt.show()
print(df.head())
# HISTOGRAM
# dataframe.col_name.hist()
df.Inches.hist()
plt.show()
df.Inches.hist(bins=14)
plt.show()
plt.figure(figsize=(10,13))
df.Inches.hist(bins=13)
plt.show()
#histogram using seaborn
plt.figure(figsize=(10,6))
sns.displot(df.Inches)
plt.show()
# pairplot
sns.pairplot(df)
plt.show()
#scatter plot matrix
from pandas.plotting import scatter_matrix
a=scatter_matrix(df,figsize=(20,20))
print(a)
#data cleaning #numerical data
df.drop('laptop_ID', axis=1,inplace= True) #dropping two columns
print(df.columns)
x = df.iloc[:,0:12].values #input
y = df.iloc[:,-1].values
print(x)
print(y)
print(y.shape)
print(x.ndim)
print(y.ndim)
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y, random_state =
0,test_size=0.2)
print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)
from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(x_train,y_train)
y_pred = model.predict(x_test)
print(y_pred) #predicted output
print(y_test) #real output
plt.scatter(y_pred,y_test)
plt.show()
#plt.plot(y_pred,y_test)
df1 = pd.DataFrame({'Actual' : y_test , 'Predicted' : y_pred })
print(df1)
#line graph representation comparing predicted v actual values
df1.plot(figsize=(20,8))
plt.show()
#line graph representation comparing predicted v actual values
df1.plot(figsize=(20,8),kind='bar')
plt.show()
#Regression plot in seaborn
plt.figure(figsize=(15,5))
plt.subplot(1,3,1)
sns.scatterplot(x='Actual', y = 'Predicted', data = df1)
plt.show()
plt.subplot(1,3,2)
sns.regplot(x='Actual', y = 'Predicted', data = df1)
plt.show()
plt.subplot(1,3,3)
sns.regplot(x='Actual', y = 'Predicted', data = df1)
plt.show()
#DATA VISUALISATION
plt.plot(x,y,color = 'g',marker = "*",markersize = 10)
plt.show()
from sklearn.metrics import r2_score
print(r2_score(y_test,y_pred)*100)